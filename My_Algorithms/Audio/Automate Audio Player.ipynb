{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import IPython.display as ipd\n",
    "\n",
    "import wave\n",
    "\n",
    "import glob\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = ['record', 'send', 'sarthi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name in dataset_names:\n",
    "    fnames = []\n",
    "    dirname = './dataset/'+str(dataset_name)+'/*.wav'\n",
    "    for fn in sorted(glob.glob(dirname)):\n",
    "        fnames.append(fn)\n",
    "    fnames_dict[str(dataset_name)] = fnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "record 168\n",
      "send 177\n",
      "sarthi 138\n"
     ]
    }
   ],
   "source": [
    "for fn, fl in fnames_dict.items():\n",
    "    print(fn, len(fl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1.wav', '113.wav', '115.wav', '116.wav', '129.wav', '131.wav', '132.wav', '133.wav', '136.wav', '137.wav', '2.wav', '22.wav', '3.wav', '7.wav', '93.wav']\n"
     ]
    }
   ],
   "source": [
    "dataname = 'sarthi'\n",
    "l = []\n",
    "count = 0\n",
    "j = 0\n",
    "for f in fnames_dict[dataname]:\n",
    "    j += 1\n",
    "    #if j == 20:\n",
    "     #   break\n",
    "    sys.stdout.write(str(f)+' count: '+str(count)+ ' '+str(j)+'\\n')\n",
    "    sys.stdout.write(str(l))\n",
    "    a_ = ipd.Audio(f, rate=16000, autoplay=True)\n",
    "    ipd.display(a_)\n",
    "    try:\n",
    "        to_store = False\n",
    "        for i in range(3):\n",
    "            time.sleep(1.0)    \n",
    "    except KeyboardInterrupt:\n",
    "        to_store = True\n",
    "    if to_store == True:\n",
    "        l.append(f.split('/')[-1])\n",
    "        count += 1\n",
    "        \n",
    "    \n",
    "    #sys.stdout.flush()\n",
    "    ipd.clear_output(wait = True)\n",
    "print(l)\n",
    "with open(dataname+'.txt', 'w+') as f:\n",
    "    for x in l:\n",
    "        f.writelines(x+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_ = ['8.wav', '57.wav', '26.wav', '41.wav', '102.wav', '107.wav', '55.wav', '105.wav', '167.wav', '7.wav', '4.wav']\n",
    "for n_ in l:\n",
    "    a_ = ipd.Audio('./dataset/record/'+n_, rate=16000, autoplay=True)\n",
    "    print(n_)\n",
    "    ipd.display(a_)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    ipd.clear_output(wait=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "record 11\n",
      "send 4\n",
      "sarthi 15\n"
     ]
    }
   ],
   "source": [
    "\n",
    "garbage_data = {}\n",
    "for dataname in dataset_names:\n",
    "    l = []\n",
    "    with open(dataname+'.txt', 'r') as f:\n",
    "        \n",
    "        for n in f.readlines():\n",
    "            #print(n)\n",
    "            l.append(n)\n",
    "        #sorted(l)\n",
    "        #print(l)\n",
    "    garbage_data[dataname] = l\n",
    "    #print('End')\n",
    "for dn, gl in garbage_data.items():\n",
    "    print(dn, len(gl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('anjali_garbage_data.txt', 'w+') as f:\n",
    "    for dataname in dataset_names:\n",
    "        f.writelines('\\nDataset: ' + dataname + '\\n')\n",
    "        for n in list(garbage_data[dataname]):\n",
    "            #print(n)\n",
    "            f.writelines(str(n)+'\\n')\n",
    "        f.writelines('\\n===========================================================\\n\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
