{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import byteorder\n",
    "from array import array\n",
    "from struct import pack\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pyaudio\n",
    "import wave\n",
    "\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "import IPython.display as ipd\n",
    "\n",
    "\n",
    "from six.moves import xrange\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "#import alsaaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.signal as sg\n",
    "from scipy.io import wavfile\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_silent(sound_data, threshold = 1300):\n",
    "    \"Returns 'True' if below the 'silent' threshold\"\n",
    "    return max(sound_data) < threshold\n",
    "\n",
    "def normalize(sound_data):\n",
    "    \"Average the volume out\"\n",
    "    MAXIMUM = 16384\n",
    "    times = float(MAXIMUM)/max(abs(i) for i in sound_data)\n",
    "\n",
    "    r = array('h')\n",
    "    for i in sound_data:\n",
    "        r.append(int(i*times))\n",
    "    return r\n",
    "\n",
    "def trim(sound_data, threshold = 1300):\n",
    "    \"Trim the blank spots at the start and end\"\n",
    "    def _trim(sound_data, threshold = 1300):\n",
    "        sound_data_started = False\n",
    "        r = array('h')\n",
    "\n",
    "        for i in sound_data:\n",
    "            if not sound_data_started and abs(i) > threshold:\n",
    "                sound_data_started = True\n",
    "                r.append(i)\n",
    "\n",
    "            elif sound_data_started:\n",
    "                r.append(i)\n",
    "        return r\n",
    "\n",
    "    # Trim to the left\n",
    "    sound_data = _trim(sound_data, threshold = threshold)\n",
    "\n",
    "    # Trim to the right\n",
    "    sound_data.reverse()\n",
    "    sound_data = _trim(sound_data, threshold = threshold)\n",
    "    sound_data.reverse()\n",
    "    return sound_data\n",
    "\n",
    "def add_silence(sound_data, pad, rate = 16000):\n",
    "    \"Add silence to the start and end of 'snd_data' of length 'seconds' (float)\"\n",
    "    pad_list = [0 for i in xrange(int(pad))]\n",
    "    r = array('h', pad_list)\n",
    "    r.extend(sound_data)\n",
    "    r.extend(pad_list)\n",
    "    return r\n",
    "\n",
    "def record(threshold = 1300, chunk_size = 1024, \n",
    "           rate = 16000, channels =1, \n",
    "           silent_limit_control = 12,\n",
    "           format_ = pyaudio.paInt16,\n",
    "           n_records = 2):\n",
    "    \"\"\"\n",
    "    Record a word or words from the microphone and \n",
    "    return the data as an array of signed shorts.\n",
    "\n",
    "    Normalizes the audio, trims silence from the \n",
    "    start and end, and pads with 0.5 seconds of \n",
    "    blank sound to make sure VLC et al can play \n",
    "    it without getting chopped off.\n",
    "    \"\"\"\n",
    "    p = pyaudio.PyAudio()\n",
    "    data = []\n",
    "    sample_width = []\n",
    "    print('n_silence: ', silent_limit_control)\n",
    "    for n_r in range(n_records):\n",
    "        print('current n_silence: ', silent_limit_control[n_r])\n",
    "        stream = p.open(format = format_, \n",
    "                        channels = channels, \n",
    "                        rate = rate,\n",
    "                        input = True, \n",
    "                        output = True,\n",
    "                        frames_per_buffer = chunk_size)\n",
    "\n",
    "        num_silent = 0\n",
    "        sound_data_started = False\n",
    "\n",
    "        r = array('h')\n",
    "\n",
    "        while 1:\n",
    "            # little endian, signed short\n",
    "            sound_data = array('h', stream.read(chunk_size))\n",
    "            print(max(sound_data))\n",
    "            if byteorder == 'big':\n",
    "                sound_data.byteswap()\n",
    "            r.extend(sound_data)\n",
    "\n",
    "            silent = is_silent(sound_data, threshold)\n",
    "\n",
    "            if silent and sound_data_started:\n",
    "                num_silent += 1\n",
    "            elif not silent and not sound_data_started:\n",
    "                sound_data_started = True\n",
    "\n",
    "            if sound_data_started and num_silent > silent_limit_control[n_r]:\n",
    "                break\n",
    "\n",
    "        sample_width.append(p.get_sample_size(format_))\n",
    "        data.append(r)\n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "        s = ipd.Audio(r, rate = rate, autoplay = True)\n",
    "        ipd.display(s)\n",
    "        \n",
    "        \n",
    "    p.terminate()\n",
    "    \n",
    "    for i in range(n_records):\n",
    "        r = data[i]\n",
    "        \n",
    "        print('len: ', len(r))\n",
    "        np_r = np.array(r, dtype = type(r))\n",
    "        print('sample_width: ', sample_width[i])\n",
    "        print('normalizing data')\n",
    "        r = normalize(r)\n",
    "        print('trimming data')\n",
    "        r = trim(r, threshold)\n",
    "        print('adding silence')\n",
    "        print('before adding silence data type: ', type(r))\n",
    "        r = add_silence(r, 0.25, rate = rate)\n",
    "        print('after adding silence data type: ', type(r))\n",
    "        time.sleep(3)\n",
    "    #print('stream rms: ', np.sqrt(np.mean(r**2)))\n",
    "    #return sample_width, r\n",
    "    return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_two_data(data, stride = 4000, window = 12000, sample_rate = 16000):\n",
    "    \n",
    "    data = np.array(data, dtype = type(data))\n",
    "    print('data: ', data.shape[0], window, stride)\n",
    "    if data.shape[0] < window:\n",
    "        raise ValueError('Data Should be atleast 12000 frames or 0.75 sec in length')\n",
    "    chunk_list = []\n",
    "    rms_list = []\n",
    "    k = 1\n",
    "    #time.sleep(2)\n",
    "    for i in range(0, data.shape[0], stride):\n",
    "        \n",
    "        chunk  = data[i: i+window]\n",
    "        rms = np.sqrt(np.mean(chunk ** 2))\n",
    "        rms_list.append(rms)\n",
    "        ch_max = chunk.max()\n",
    "        ch_min = chunk.min()\n",
    "        print('chunk : ', str(k), ' rms: ', rms, 'min: ', ch_min, 'max: ', ch_max)\n",
    "        print('difference: ', ch_max- ch_min)\n",
    "        k += 1\n",
    "        sound = ipd.Audio(chunk, rate = sample_rate, autoplay = True)\n",
    "        ipd.display(sound)\n",
    "        time.sleep(0.5)\n",
    "    #print(rms)\n",
    "    #idxs = np.argsort(rms)[-2:]\n",
    "    #print(np.argsort(rms))\n",
    "    \n",
    "    #return chunk_list[]\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_to_file(path = './demo_.wav', threshold = 1300, \n",
    "                   chunk_size = 1024, rate = 16000, \n",
    "                   channels =1, silent_limit_control = 12,\n",
    "                   format_ = pyaudio.paInt16,\n",
    "                   stride = 4000, window = 12000):\n",
    "    \"Records from the microphone and outputs the resulting data to 'path'\"\n",
    "    sample_width, data = record(threshold, chunk_size, rate, \n",
    "                                channels, silent_limit_control, format_)\n",
    "    \"\"\"\n",
    "    print('IN record_to_file')\n",
    "    print('Type of recorded data: ', type(data))\n",
    "    \n",
    "    sound = ipd.Audio(data, rate = rate, autoplay = True)\n",
    "    ipd.display(sound)\n",
    "    \n",
    "    print('Recording Happen Successfully')\n",
    "    print('we can check for rms before saving')\n",
    "    time.sleep(2.0)\n",
    "    get_top_two_data(data, stride = stride, window = window, sample_rate = rate)\n",
    "    \n",
    "    \n",
    "    #data_ = pack('<' + ('h'*len(data)), *data)\n",
    "    print('Saving recorded data to: ', path)\n",
    "    wf = wave.open(path, 'wb')\n",
    "    wf.setnchannels(1)\n",
    "    wf.setsampwidth(sample_width)\n",
    "    wf.setframerate(rate)\n",
    "    wf.writeframes(np.array(data))\n",
    "    wf.close()\n",
    "    print('Recorded data saved and now returning data: ', np.array(data).shape)\n",
    "    return data\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    \n",
    "def check_audio_duration(fname = './word_1.wav', rate = 16000):\n",
    "    f = wave.open(fname, 'r')\n",
    "    frames = f.getnframes()\n",
    "    rate = f.getframerate()\n",
    "    duration = (frames / float(rate)) * 1000\n",
    "    #print('sample rate = ', rate)\n",
    "    print('seconds = ', duration/1000)\n",
    "    print('IN check_audio_duration')\n",
    "    sound = ipd.Audio(fname, rate = rate, autoplay = True)\n",
    "    ipd.display(sound)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_for_silence(wave_file = './demo.wav', out_file1 = './word1.wav', \n",
    "                     out_file2 = './word2.wav',\n",
    "                     pad = 2000, file_format = 'wav', r = None, id_ = 'sr'):        \n",
    "    average_loudness_l = []\n",
    "    loudness_l = []\n",
    "    max_amp_l = []\n",
    "    ratio_l = []\n",
    "    n_segments_l = []\n",
    "    i = 0\n",
    "    \n",
    "    print('Reading File using wave.open: ', wave_file)\n",
    "    f = wave.open(wave_file, 'r')\n",
    "    frames = f.getnframes()\n",
    "    print('n_frames: ', frames)\n",
    "    rate = f.getframerate()\n",
    "    print('sample rate: ', rate)\n",
    "    duration = (frames / float(rate)) * 1000\n",
    "    print('duration: ', duration)\n",
    "    #print('sample rate = ', rate)\n",
    "    #print('seconds = ', duration/1000)\n",
    "    \n",
    "    print('pad : ', pad)\n",
    "    \n",
    "    print(type(r))\n",
    "    #r = add_silence(r, pad)\n",
    "    \n",
    "    \n",
    "    #\"\"\"\n",
    "    if id_ == 'dcr':\n",
    "        min_silence_len = min(600, int(duration/4.0))    \n",
    "    #for data_collector_recorder\n",
    "    \n",
    "    elif id_ == 'sr':\n",
    "        min_silence_len = min(300, int(duration/3.0))\n",
    "    #\n",
    "    #print('min_silence lenth should be : ',min_silence_len)\n",
    "\n",
    "    #ipd.Audio(filename = wav_file, rate = 16000)\n",
    "    print('Reading file using AudioSegment.from_wave: ', wave_file)\n",
    "    sound = AudioSegment.from_wav(wave_file)\n",
    "    average_loudness = sound.rms\n",
    "    average_loudness_l.append(average_loudness)\n",
    "    #print('average_loudness : ', average_loudness)\n",
    "    print('sound rms: ', average_loudness)\n",
    "    print('stream rms: ', np.sqrt(np.mean(np.array(r, dtype = type(r))**2)))\n",
    "\n",
    "\n",
    "    loudness = sound.dBFS\n",
    "    loudness_l.append(loudness)\n",
    "    #print('loudness : ', loudness)\n",
    "\n",
    "    max_amp = sound.max_possible_amplitude\n",
    "    max_amp_l.append(max_amp)\n",
    "    #print('log max_amp  : ', np.log10(max_amp)*20)\n",
    "\n",
    "    ratio = 20 * np.log10(average_loudness / max_amp)\n",
    "    ratio_l.append(ratio)\n",
    "    #print('ratio - avg loudness / max_amp  : ', ratio)\n",
    "\n",
    "    n_segments = -1\n",
    "    s_t = np.round(33.0, 2)\n",
    "    return r\n",
    "    \"\"\"\n",
    "    audio_segments = split_on_silence(sound,\n",
    "                                      min_silence_len = min_silence_len,\n",
    "                                      keep_silence = keep_silence,\n",
    "                                      silence_thresh = -1 * s_t)\n",
    "    n_segments = len(audio_segments)\n",
    "    max_idx = 0\n",
    "    rms_list = []\n",
    "    \n",
    "    \n",
    "    print(\"type of f \", type(f))\n",
    "    for k, seg in enumerate(audio_segments):\n",
    "        print('j = ',k,' rms: ', seg.rms, 'dBFS: ', seg.dBFS, 'max_amp: ', seg.max_possible_amplitude)\n",
    "        print('\\t ratio: ', 20*np.log10(seg.rms/seg.max_possible_amplitude))\n",
    "        print(\"type of segment\", type(seg))\n",
    "        print(\"number of frames: \",(np.array(seg).shape[0])*16)\n",
    "        rms_list.append(seg.rms)\n",
    "        #print()\n",
    "    rms_list = np.array(rms_list)\n",
    "    #idx = np.argmax(rms_list)\n",
    "    #idxs = np.arange(rms_list.shape[0])\n",
    "    idxs = np.sort(np.argsort(rms_list)[-2:])\n",
    "    #print('number of segments : ', n_segments, 'max idx = ', idx)\n",
    "    \n",
    "    #if n_segments == 1:\n",
    "\n",
    "\n",
    "    audio_segments[idxs[0]].export(out_file1, format = file_format)\n",
    "    audio_segments[idxs[1]].export(out_file2, format = file_format)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_recorder(fname_path = './recordings/', \n",
    "                    keep_silence = 20, threshold = 1300, \n",
    "                    chunk_size = 1024, \n",
    "                    rate = 16000, channels = 1, \n",
    "                    silent_limit_control = 6,\n",
    "                    window = 12000,\n",
    "                    stride = 4000):\n",
    "    id_ = 'sr'\n",
    "    format_ = pyaudio.paInt16\n",
    "    wave_list = []\n",
    "    if not os.path.exists(fname_path):\n",
    "                os.makedirs(fname_path)\n",
    "    \n",
    "    if not os.path.exists(fname_path + '/word/'):\n",
    "                os.makedirs(fname_path + '/word/')\n",
    "    for i in range(1):\n",
    "        print(\"please speak a words into the microphone\")\n",
    "        time.sleep(0.5)\n",
    "        record_fname = fname_path + '/demo_' + str(i+1) + '.wav'\n",
    "        #r = record_to_file(record_fname, threshold, chunk_size, rate, channels, silent_limit_control, format_)\n",
    "        record_to_file(record_fname, \n",
    "                       threshold,\n",
    "                       chunk_size,\n",
    "                       rate, \n",
    "                       channels,\n",
    "                       silent_limit_control,\n",
    "                       format_,\n",
    "                       window = window,\n",
    "                       stride = stride)\n",
    "        \"\"\"\n",
    "        print(type(r))\n",
    "        \n",
    "        sound = AudioSegment.from_wav(record_fname)\n",
    "        print(\"shape:  \", np.array(sound).shape)\n",
    "        print(len(np.array(sound).shape))\n",
    "        check_audio_duration(record_fname, rate = rate)\n",
    "        time.sleep(1)\n",
    "        r_ = clip_for_silence(wave_file = record_fname, r = r)\n",
    "        print('IN start_recorder')\n",
    "        sound = ipd.Audio(r_, rate = rate, autoplay = True)\n",
    "        ipd.display(sound)\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "please speak a words into the microphone\n",
      "n_silence:  [2, 6]\n",
      "current n_silence:  2\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno -9997] Invalid sample rate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-c90f487d89cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                \u001b[0mwindow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                \u001b[0mstride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                silent_limit_control = [2, 6]  )\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-fddd5900c42c>\u001b[0m in \u001b[0;36mstart_recorder\u001b[0;34m(fname_path, keep_silence, threshold, chunk_size, rate, channels, silent_limit_control, window, stride)\u001b[0m\n\u001b[1;32m     27\u001b[0m                        \u001b[0mformat_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                        \u001b[0mwindow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                        stride = stride)\n\u001b[0m\u001b[1;32m     30\u001b[0m         \"\"\"\n\u001b[1;32m     31\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-94e12446cf23>\u001b[0m in \u001b[0;36mrecord_to_file\u001b[0;34m(path, threshold, chunk_size, rate, channels, silent_limit_control, format_, stride, window)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;34m\"Records from the microphone and outputs the resulting data to 'path'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     sample_width, data = record(threshold, chunk_size, rate, \n\u001b[0;32m----> 8\u001b[0;31m                                 channels, silent_limit_control, format_)\n\u001b[0m\u001b[1;32m      9\u001b[0m     \"\"\"\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'IN record_to_file'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-233e6963d94c>\u001b[0m in \u001b[0;36mrecord\u001b[0;34m(threshold, chunk_size, rate, channels, silent_limit_control, format_, n_records)\u001b[0m\n\u001b[1;32m     70\u001b[0m                         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m                         frames_per_buffer = chunk_size)\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mnum_silent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai/lib/python3.6/site-packages/pyaudio.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    748\u001b[0m         \"\"\"\n\u001b[1;32m    749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m         \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_streams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai/lib/python3.6/site-packages/pyaudio.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, PA_manager, rate, channels, format, input, output, input_device_index, output_device_index, frames_per_buffer, start, input_host_api_specific_stream_info, output_host_api_specific_stream_info, stream_callback)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;31m# calling pa.open returns a stream object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_latency\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputLatency\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno -9997] Invalid sample rate"
     ]
    }
   ],
   "source": [
    "start_recorder(threshold = 1000,\n",
    "               chunk_size = 2048,\n",
    "               window = 8000,\n",
    "               stride = 4000,\n",
    "               silent_limit_control = [2, 6]  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "16384/16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
